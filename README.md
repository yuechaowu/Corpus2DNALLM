# Corpus2DNALLM

å°†åŸºå› ç»„æ•°æ®è½¬æ¢ä¸ºDNAè¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®çš„å®Œæ•´å·¥å…·é“¾

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Bioinformatics](https://img.shields.io/badge/Bioinformatics-DNA%20Sequences-orange)](https://en.wikipedia.org/wiki/Bioinformatics)

## ğŸ“– ç®€ä»‹

Corpus2DNALLM æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”Ÿç‰©ä¿¡æ¯å­¦å·¥å…·ï¼Œç”¨äºå°†åŸºå› ç»„åºåˆ—æ•°æ®è½¬æ¢ä¸ºé€‚åˆDNAè¯­è¨€æ¨¡å‹è®­ç»ƒçš„è¯­æ–™åº“ã€‚è¯¥å·¥å…·é›†æˆäº†å®Œæ•´çš„å¤„ç†æµç¨‹ï¼Œä»åŸå§‹åŸºå› ç»„FASTAæ–‡ä»¶åˆ°æœ€ç»ˆçš„åˆ†è¯å™¨é…ç½®æ–‡ä»¶ã€‚

### ä¸»è¦åŠŸèƒ½

- ğŸ” **åŸºå› ç»„æ–‡ä»¶æ£€æŸ¥å’Œå¤§å°ç»Ÿè®¡** - è‡ªåŠ¨æ£€æŸ¥åŸºå› ç»„æ–‡ä»¶å®Œæ•´æ€§å¹¶ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
- ğŸ“š **è¯­æ–™åº“å‡†å¤‡** - æ™ºèƒ½æ‹†åˆ†åŸºå› ç»„åºåˆ—ï¼Œç”Ÿæˆè®­ç»ƒè¯­æ–™åº“
- ğŸ”§ **BPEåˆ†è¯å™¨è®­ç»ƒ** - ä½¿ç”¨SentencePieceè®­ç»ƒé«˜æ€§èƒ½BPEåˆ†è¯å™¨
- âš™ï¸ **é…ç½®æ–‡ä»¶ç”Ÿæˆ** - ç”ŸæˆHuggingFace Transformerså…¼å®¹çš„é…ç½®æ–‡ä»¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/Corpus2DNALLM.git
cd Corpus2DNALLM

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# æˆ– .venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -e .
```

### åŸºæœ¬ä½¿ç”¨

#### 1. æ‰§è¡Œå®Œæ•´æµç¨‹

```bash
corpus2dnallm all \
    --genomes-info-path data/genomes_info.tsv \
    --masked-dir data/masked/ \
    --unmasked-dir data/unmasked/ \
    --output-dir output/
```

#### 2. åˆ†æ­¥éª¤æ‰§è¡Œ

```bash
# æ­¥éª¤1: å‡†å¤‡åŸºå› ç»„
corpus2dnallm prepare-genome \
    --genomes-info-path data/genomes_info.tsv \
    --masked-dir data/masked/ \
    --unmasked-dir data/unmasked/ \
    --output-dir output/

# æ­¥éª¤2: å‡†å¤‡è¯­æ–™åº“
corpus2dnallm prepare-corpus \
    --genomes-info-path data/genomes_info.tsv \
    --unmasked-dir data/unmasked/ \
    --split-mask-dir output/hardmask_split/ \
    --genome-size-file output/genome_sizes.txt \
    --output-file output/corpus.txt

# æ­¥éª¤3: è®­ç»ƒåˆ†è¯å™¨
corpus2dnallm train-tokenizer \
    --input-file output/corpus.txt \
    --model-prefix output/dna_tokenizer \
    --vocab-size 8192

# æ­¥éª¤4: ç”Ÿæˆé…ç½®æ–‡ä»¶
corpus2dnallm generate-config \
    --model-path output/dna_tokenizer.model \
    --example-config-file examples/tokenizer_config.json \
    --example-tokenizer-file examples/tokenizer.json \
    --output-dir output/
```

## ğŸ“‹ å‘½ä»¤å‚è€ƒ

### ä¸»å‘½ä»¤

```bash
corpus2dnallm [å­å‘½ä»¤] [é€‰é¡¹]
```

### å­å‘½ä»¤

#### `prepare-genome` - åŸºå› ç»„å‡†å¤‡

æ£€æŸ¥åŸºå› ç»„æ–‡ä»¶å¹¶ç”Ÿæˆå¤§å°ç»Ÿè®¡ä¿¡æ¯ã€‚

**å‚æ•°:**
- `--genomes-info-path`: åŒ…å«åŸºå› ç»„ä¿¡æ¯çš„TSVæ–‡ä»¶è·¯å¾„
- `--masked-dir`: hardmaskedåŸºå› ç»„æ–‡ä»¶ç›®å½•
- `--unmasked-dir`: unmaskedåŸºå› ç»„æ–‡ä»¶ç›®å½•
- `--output-dir`: è¾“å‡ºç›®å½•

**è¾“å‡ºæ–‡ä»¶:**
- `genome_sizes.txt` - åŸºå› ç»„ç»Ÿè®¡ä¿¡æ¯
- `hardmask_split/` - æŒ‰NåŒºåŸŸæ‹†åˆ†çš„maskedåºåˆ—

#### `prepare-corpus` - è¯­æ–™åº“å‡†å¤‡

ä»åŸºå› ç»„æ–‡ä»¶ç”Ÿæˆè®­ç»ƒè¯­æ–™åº“ã€‚

**å‚æ•°:**
- `--genomes-info-path`: åŸºå› ç»„ä¿¡æ¯æ–‡ä»¶è·¯å¾„
- `--unmasked-dir`: unmaskedåŸºå› ç»„æ–‡ä»¶ç›®å½•
- `--split-mask-dir`: åˆ†å‰²çš„maskedæ–‡ä»¶ç›®å½•
- `--genome-size-file`: åŸºå› ç»„å¤§å°æ–‡ä»¶è·¯å¾„
- `--output-file`: è¾“å‡ºè¯­æ–™åº“æ–‡ä»¶è·¯å¾„
- `--max-seq-length`: æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: 4000)
- `--genome-split-size`: åŸºå› ç»„æ‹†åˆ†å¤§å°é˜ˆå€¼(MB) (é»˜è®¤: 500)

**å¤„ç†é€»è¾‘:**
- å°äº500MBçš„åŸºå› ç»„: ä½¿ç”¨å…¨éƒ¨unmaskedåºåˆ—
- å¤§äº500MBçš„åŸºå› ç»„: æ··åˆä½¿ç”¨maskedå’Œunmaskedåºåˆ—

#### `train-tokenizer` - åˆ†è¯å™¨è®­ç»ƒ

è®­ç»ƒBPEåˆ†è¯å™¨æ¨¡å‹ã€‚

**å‚æ•°:**
- `--input-file`: è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
- `--model-prefix`: è¾“å‡ºæ¨¡å‹æ–‡ä»¶å‰ç¼€
- `--vocab-size`: è¯æ±‡è¡¨å¤§å° (é»˜è®¤: 8192)
- `--model-type`: æ¨¡å‹ç±»å‹ (é»˜è®¤: bpe)
- `--num-threads`: è®­ç»ƒçº¿ç¨‹æ•° (é»˜è®¤: 4)

**è¾“å‡ºæ–‡ä»¶:**
- `{model_prefix}.model` - SentencePieceæ¨¡å‹æ–‡ä»¶
- `{model_prefix}.vocab` - è¯æ±‡è¡¨æ–‡ä»¶

#### `generate-config` - é…ç½®ç”Ÿæˆ

ç”ŸæˆHuggingFaceå…¼å®¹çš„é…ç½®æ–‡ä»¶ã€‚

**å‚æ•°:**
- `--model-path`: BPEæ¨¡å‹æ–‡ä»¶è·¯å¾„
- `--example-config-file`: ç¤ºä¾‹tokenizeré…ç½®æ–‡ä»¶è·¯å¾„
- `--example-tokenizer-file`: ç¤ºä¾‹tokenizeræ–‡ä»¶è·¯å¾„
- `--output-dir`: è¾“å‡ºç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)
- `--special-token-file`: ç‰¹æ®Šæ ‡è®°JSONæ–‡ä»¶è·¯å¾„ (å¯é€‰)

**è¾“å‡ºæ–‡ä»¶:**
- `vocab.json` - è¯æ±‡è¡¨æ–‡ä»¶
- `merges.txt` - BPEåˆå¹¶è§„åˆ™æ–‡ä»¶
- `tokenizer_config.json` - tokenizeré…ç½®æ–‡ä»¶
- `tokenizer.json` - tokenizerå®šä¹‰æ–‡ä»¶

## ğŸ“ è¾“å…¥æ–‡ä»¶æ ¼å¼

### åŸºå› ç»„ä¿¡æ¯æ–‡ä»¶ (`genomes_info.tsv`)

TSVæ ¼å¼ï¼ŒåŒ…å«åŸºå› ç»„åç§°å’Œç±»å‹ï¼š

```tsv
genome_name    genome_type
human          both
mouse          both
yeast          unmasked
```

- `genome_name`: åŸºå› ç»„åç§° (å°å†™)
- `genome_type`: `both` (æœ‰maskedå’Œunmasked) æˆ– `unmasked` (åªæœ‰unmasked)

### åŸºå› ç»„æ–‡ä»¶

æ”¯æŒå¤šç§FASTAæ ¼å¼ï¼š
- `.fa`, `.fasta` - æœªå‹ç¼©FASTA
- `.fa.gz`, `.fasta.gz` - gzipå‹ç¼©FASTA

æ–‡ä»¶å‘½åç¤ºä¾‹ï¼š
- `human.fa.gz`
- `mouse.fasta`
- `yeast.fa`

## ğŸ”„ å·¥ä½œæµç¨‹

```mermaid
graph TD
    A[åŸºå› ç»„ä¿¡æ¯æ–‡ä»¶] --> B[æ£€æŸ¥åŸºå› ç»„æ–‡ä»¶]
    C[masked FASTAæ–‡ä»¶] --> B
    D[unmasked FASTAæ–‡ä»¶] --> B

    B --> E[ç”ŸæˆåŸºå› ç»„ç»Ÿè®¡]
    B --> F[æ‹†åˆ†maskedåºåˆ—]

    E --> G[å‡†å¤‡è¯­æ–™åº“]
    F --> G

    G --> H[è®­ç»ƒBPEåˆ†è¯å™¨]
    H --> I[ç”Ÿæˆé…ç½®æ–‡ä»¶]

    style A fill:#e1f5fe
    style C fill:#e8f5e8
    style D fill:#e8f5e8
    style I fill:#fff3e0
```

## ğŸ“Š å¤„ç†ç­–ç•¥

### åºåˆ—é€‰æ‹©ç­–ç•¥

| åŸºå› ç»„å¤§å° | å¤„ç†æ–¹å¼ | è¯´æ˜ |
|------------|----------|------|
| < 500MB | å…¨éƒ¨unmaskedåºåˆ— | é€‚ç”¨äºå°åŸºå› ç»„ |
| â‰¥ 500MB | æ··åˆç­–ç•¥ | 250MB masked + 250MB unmasked |

### åºåˆ—æ‹†åˆ†è§„åˆ™

- **æœ€å¤§é•¿åº¦**: 4000ä¸ªç¢±åŸº (å¯é…ç½®)
- **æœ€å°é•¿åº¦**: 100ä¸ªç¢±åŸº (è¿‡æ»¤è¿‡çŸ­åºåˆ—)
- **ç‰¹æ®Šå­—ç¬¦**: è½¬æ¢ä¸ºå¤§å†™å­—æ¯
- **maskedåŒºåŸŸ**: æŒ‰Nå­—ç¬¦åºåˆ—åˆ†å‰²

## âš™ï¸ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®æ—¥å¿—çº§åˆ«
export CORPUS2DNALLM_LOG_LEVEL=INFO

# è®¾ç½®ä¸´æ—¶ç›®å½•
export CORPUS2DNALLM_TEMP_DIR=/tmp/corpus2dnallm

# è®¾ç½®çº¿ç¨‹æ•°
export CORPUS2DNALLM_NUM_THREADS=8
```

### é«˜çº§å‚æ•°

```bash
# è‡ªå®šä¹‰BPEå‚æ•°
corpus2dnallm train-tokenizer \
    --vocab-size 16384 \
    --model-type unigram \
    --character-coverage 0.9999 \
    --num-sub-iterations 2
```

## ğŸ”§ å¼€å‘

### æœ¬åœ°å¼€å‘

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/Corpus2DNALLM.git
cd Corpus2DNALLM

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œæµ‹è¯•
pytest

# ä»£ç æ ¼å¼åŒ–
black src/
flake8 src/
```

### é¡¹ç›®ç»“æ„

```
Corpus2DNALLM/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ corpus2dnallm/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cli.py              # CLIå…¥å£ç‚¹
â”‚       â”œâ”€â”€ genome_size.py      # åŸºå› ç»„å¤§å°ç»Ÿè®¡
â”‚       â”œâ”€â”€ corpus_prep.py      # è¯­æ–™åº“å‡†å¤‡
â”‚       â”œâ”€â”€ tokenizer_train.py  # åˆ†è¯å™¨è®­ç»ƒ
â”‚       â””â”€â”€ config_gen.py       # é…ç½®ç”Ÿæˆ
â”œâ”€â”€ data/                       # ç¤ºä¾‹æ•°æ®
â”œâ”€â”€ examples/                   # ç¤ºä¾‹é…ç½®æ–‡ä»¶
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ pyproject.toml             # é¡¹ç›®é…ç½®
â””â”€â”€ README.md                  # æœ¬æ–‡æ¡£
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–

- ä½¿ç”¨æµå¼å¤„ç†ï¼Œé¿å…å°†æ•´ä¸ªåŸºå› ç»„åŠ è½½åˆ°å†…å­˜
- è‡ªåŠ¨è°ƒæ•´ç¼“å†²åŒºå¤§å°
- æ”¯æŒgzipå‹ç¼©æ–‡ä»¶ç›´æ¥å¤„ç†

### é€Ÿåº¦ä¼˜åŒ–

- å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
- æ™ºèƒ½ç¼“å­˜æœºåˆ¶
- æ‰¹é‡IOæ“ä½œ

### æ¨èé…ç½®

```bash
# å¤§åŸºå› ç»„å¤„ç†å»ºè®®
export CORPUS2DNALLM_NUM_THREADS=16
export CORPUS2DNALLM_BUFFER_SIZE=1048576  # 1MB
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: æç¤º"åŸºå› ç»„æ–‡ä»¶ä¸å­˜åœ¨"**

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- æ–‡ä»¶å‘½åæ˜¯å¦ç¬¦åˆè§„èŒƒ
- æ˜¯å¦æœ‰ç›¸åº”çš„æ–‡ä»¶æƒé™

**Q: å†…å­˜ä¸è¶³é”™è¯¯**

A: å°è¯•ä»¥ä¸‹è§£å†³æ–¹æ¡ˆï¼š
- å‡å°‘çº¿ç¨‹æ•°: `--num-threads 2`
- å‡å°åºåˆ—é•¿åº¦: `--max-seq-length 2000`
- ä½¿ç”¨æ›´å°çš„åŸºå› ç»„æ‹†åˆ†å¤§å°

**Q: åˆ†è¯å™¨è®­ç»ƒå¤±è´¥**

A: æ£€æŸ¥ï¼š
- è¯­æ–™åº“æ–‡ä»¶æ˜¯å¦ä¸ºç©º
- è¯æ±‡è¡¨å¤§å°æ˜¯å¦åˆç†
- è¾“å…¥æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸ºUTF-8

### æ—¥å¿—è°ƒè¯•

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
corpus2dnallm --verbose all [å‚æ•°]

# æˆ–è®¾ç½®ç¯å¢ƒå˜é‡
export CORPUS2DNALLM_LOG_LEVEL=DEBUG
```

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **SentencePiece**: [Unsupervised Text Segmentation for Neural Language Models](https://arxiv.org/abs/1804.10959)
2. **BPE**: [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909)
3. **HuggingFace Tokenizers**: [ğŸ¤— Tokenizers](https://huggingface.co/docs/tokenizers/)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£è¯¦ç»†ä¿¡æ¯ã€‚

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: https://github.com/yourusername/Corpus2DNALLM
- é—®é¢˜åé¦ˆ: https://github.com/yourusername/Corpus2DNALLM/issues
- é‚®ç®±: your.email@example.com

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºç”Ÿç‰©ä¿¡æ¯å­¦å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸåšå‡ºè´¡çŒ®çš„ç ”ç©¶è€…ä»¬ã€‚

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼